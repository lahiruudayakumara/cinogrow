"""simplify_plot_model_computed_properties

Revision ID: 07fa7e129ca8
Revises: add_hybrid_tree_tables
Create Date: 2025-11-29 22:36:13.549535

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '07fa7e129ca8'
down_revision = 'add_hybrid_tree_tables'
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_model_performance_metrics_metric_id'), table_name='model_performance_metrics')
    op.drop_table('model_performance_metrics')
    op.drop_index(op.f('ix_continuous_learning_config_config_name'), table_name='continuous_learning_config')
    op.drop_table('continuous_learning_config')
    op.drop_table('c_avg_dataset')
    op.drop_index(op.f('ix_training_datasets_dataset_id'), table_name='training_datasets')
    op.drop_table('training_datasets')
    op.drop_index(op.f('ix_user_feedback_feedback_id'), table_name='user_feedback')
    op.drop_table('user_feedback')
    op.drop_table('tree_harvest_records')
    op.drop_table('tree_measurements')
    op.drop_index(op.f('ix_image_annotations_annotation_id'), table_name='image_annotations')
    op.drop_table('image_annotations')
    op.drop_table('image_analysis_logs')
    op.drop_index(op.f('ix_continuous_learning_configs_config_id'), table_name='continuous_learning_configs')
    op.drop_table('continuous_learning_configs')
    op.drop_index(op.f('ix_model_deployments_deployment_id'), table_name='model_deployments')
    op.drop_table('model_deployments')
    op.drop_index(op.f('ix_model_training_runs_run_id'), table_name='model_training_runs')
    op.drop_table('model_training_runs')
    op.drop_table('trees')
    op.drop_column('plots', 'status')
    op.drop_column('plots', 'max_stem_diameter_mm')
    op.drop_column('plots', 'fertilizer_used_plot')
    op.drop_column('plots', 'age_months')
    op.drop_column('plots', 'planting_date')
    op.drop_column('plots', 'diameter_variability')
    op.drop_column('plots', 'avg_stem_diameter_mm')
    op.drop_column('plots', 'trees_per_hectare')
    op.drop_column('plots', 'tree_count')
    op.drop_column('plots', 'min_stem_diameter_mm')
    op.drop_column('plots', 'expected_harvest_date')
    op.drop_column('plots', 'progress_percentage')
    op.drop_column('plots', 'disease_present_plot')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('plots', sa.Column('disease_present_plot', sa.VARCHAR(length=20), server_default=sa.text("'none'::character varying"), autoincrement=False, nullable=True))
    op.add_column('plots', sa.Column('progress_percentage', sa.INTEGER(), autoincrement=False, nullable=False))
    op.add_column('plots', sa.Column('expected_harvest_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.add_column('plots', sa.Column('min_stem_diameter_mm', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('plots', sa.Column('tree_count', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('plots', sa.Column('trees_per_hectare', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('plots', sa.Column('avg_stem_diameter_mm', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('plots', sa.Column('diameter_variability', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('plots', sa.Column('planting_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.add_column('plots', sa.Column('age_months', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('plots', sa.Column('fertilizer_used_plot', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=True))
    op.add_column('plots', sa.Column('max_stem_diameter_mm', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('plots', sa.Column('status', postgresql.ENUM('PREPARING', 'PLANTED', 'GROWING', 'MATURE', 'HARVESTING', 'HARVESTED', 'RESTING', name='plotstatus'), autoincrement=False, nullable=False))
    op.create_table('trees',
    sa.Column('id', sa.INTEGER(), server_default=sa.text("nextval('trees_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('plot_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('tree_code', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('location_x', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('location_y', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('planting_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('variety', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('tree_age_years', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('stem_count', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('is_active', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('last_harvest_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('fertilizer_used', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('fertilizer_type', postgresql.ENUM('ORGANIC', 'NPK', 'UREA', 'COMPOST', 'NONE', name='fertilizertype'), autoincrement=False, nullable=True),
    sa.Column('fertilizer_application_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('disease_status', postgresql.ENUM('NONE', 'MILD', 'SEVERE', name='diseasestatus'), autoincrement=False, nullable=False),
    sa.Column('disease_notes', sa.VARCHAR(length=500), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['plot_id'], ['plots.id'], name='trees_plot_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='trees_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_table('model_training_runs',
    sa.Column('id', sa.INTEGER(), server_default=sa.text("nextval('model_training_runs_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('run_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('dataset_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('model_type', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('model_architecture', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('hyperparameters', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('status', postgresql.ENUM('PENDING', 'IN_PROGRESS', 'COMPLETED', 'FAILED', 'CANCELLED', name='trainingstatus'), autoincrement=False, nullable=False),
    sa.Column('current_epoch', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('total_epochs', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('training_accuracy', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('validation_accuracy', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('test_accuracy', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('training_loss', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('validation_loss', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('class_metrics', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('confusion_matrix', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('feature_importance', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('training_time_seconds', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('hardware_info', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('model_path', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('weights_path', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('config_path', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('started_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('completed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('started_by', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('notes', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['dataset_id'], ['training_datasets.dataset_id'], name='model_training_runs_dataset_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='model_training_runs_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('ix_model_training_runs_run_id'), 'model_training_runs', ['run_id'], unique=True)
    op.create_table('model_deployments',
    sa.Column('id', sa.INTEGER(), server_default=sa.text("nextval('model_deployments_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('deployment_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('training_run_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('version', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('environment', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('api_endpoint', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('is_active', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('is_default', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('total_predictions', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('successful_predictions', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('error_count', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('total_feedback_count', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('average_accuracy_rating', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('positive_feedback_percentage', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('deployed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('deployed_by', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('deactivated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('deactivated_by', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['training_run_id'], ['model_training_runs.run_id'], name='model_deployments_training_run_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='model_deployments_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('ix_model_deployments_deployment_id'), 'model_deployments', ['deployment_id'], unique=True)
    op.create_table('continuous_learning_configs',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('config_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('retrain_threshold_accuracy', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('feedback_count_threshold', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('drift_score_threshold', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('auto_retrain_enabled', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('retrain_frequency_days', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('next_scheduled_retrain', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('min_new_samples_for_retrain', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('min_annotation_confidence', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('validation_accuracy_threshold', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('min_improvement_threshold', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('auto_deployment_enabled', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('canary_deployment_percentage', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('rollback_on_error_rate', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('created_by', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('is_active', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('continuous_learning_configs_pkey'))
    )
    op.create_index(op.f('ix_continuous_learning_configs_config_id'), 'continuous_learning_configs', ['config_id'], unique=True)
    op.create_table('image_analysis_logs',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('original_filename', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('image_size_bytes', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('image_dimensions', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('image_format', sa.VARCHAR(length=20), autoincrement=False, nullable=True),
    sa.Column('preprocessing_steps', sa.VARCHAR(length=500), autoincrement=False, nullable=True),
    sa.Column('model_used', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('processing_duration_ms', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('analysis_success', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('error_message', sa.VARCHAR(length=1000), autoincrement=False, nullable=True),
    sa.Column('confidence_threshold_met', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('image_analysis_logs_pkey'))
    )
    op.create_table('image_annotations',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('annotation_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('image_analysis_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('image_path', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('primary_deficiency', postgresql.ENUM('NITROGEN_DEFICIENCY', 'PHOSPHORUS_DEFICIENCY', 'POTASSIUM_DEFICIENCY', 'HEALTHY', name='deficiencytype'), autoincrement=False, nullable=False),
    sa.Column('severity_level', postgresql.ENUM('MILD', 'MODERATE', 'SEVERE', name='severitylevel'), autoincrement=False, nullable=False),
    sa.Column('confidence_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('secondary_deficiencies', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('affected_area_percentage', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('annotated_regions', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('symptom_descriptions', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('visual_cues', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('label_source', postgresql.ENUM('EXPERT_MANUAL', 'FARMER_FEEDBACK', 'FIELD_VALIDATION', 'LABORATORY_TEST', 'AUTO_GENERATED', name='labelsource'), autoincrement=False, nullable=False),
    sa.Column('annotator_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('verified', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('verified_by', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('verification_notes', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['image_analysis_id'], ['ml_image_analyses.analysis_id'], name=op.f('image_annotations_image_analysis_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('image_annotations_pkey'))
    )
    op.create_index(op.f('ix_image_annotations_annotation_id'), 'image_annotations', ['annotation_id'], unique=True)
    op.create_table('tree_measurements',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('tree_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('measurement_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('measured_by', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('stem_diameter_mm', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('num_existing_stems', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('stem_length_cm', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('stem_thickness_variability', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('canopy_coverage', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('leaf_health_score', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('pest_damage', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('soil_moisture', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('rainfall_recent_mm', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('temperature_recent_c', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('actual_canes', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('actual_fresh_weight_kg', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('actual_dry_weight_kg', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('notes', sa.VARCHAR(length=1000), autoincrement=False, nullable=True),
    sa.Column('is_training_data', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['tree_id'], ['trees.id'], name=op.f('tree_measurements_tree_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('tree_measurements_pkey'))
    )
    op.create_table('tree_harvest_records',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('tree_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('harvest_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('harvested_by', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('canes_harvested', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('fresh_bark_weight_kg', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('dry_bark_weight_kg', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('bark_quality_grade', sa.VARCHAR(length=20), autoincrement=False, nullable=True),
    sa.Column('stems_remaining', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('tree_health_after_harvest', sa.VARCHAR(length=200), autoincrement=False, nullable=True),
    sa.Column('price_per_kg', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('total_revenue', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('notes', sa.VARCHAR(length=500), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['tree_id'], ['trees.id'], name=op.f('tree_harvest_records_tree_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('tree_harvest_records_pkey'))
    )
    op.create_table('user_feedback',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('feedback_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('analysis_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('session_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('farm_location', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('feedback_type', postgresql.ENUM('ACCURACY_RATING', 'RECOMMENDATION_EFFECTIVENESS', 'OUTCOME_REPORT', 'ERROR_REPORT', name='feedbacktype'), autoincrement=False, nullable=False),
    sa.Column('predicted_deficiency', postgresql.ENUM('NITROGEN_DEFICIENCY', 'PHOSPHORUS_DEFICIENCY', 'POTASSIUM_DEFICIENCY', 'HEALTHY', name='deficiencytype'), autoincrement=False, nullable=True),
    sa.Column('actual_deficiency', postgresql.ENUM('NITROGEN_DEFICIENCY', 'PHOSPHORUS_DEFICIENCY', 'POTASSIUM_DEFICIENCY', 'HEALTHY', name='deficiencytype'), autoincrement=False, nullable=True),
    sa.Column('accuracy_rating', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('recommendation_followed', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('effectiveness_rating', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('improvement_observed', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('days_to_improvement', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('feedback_text', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('issues_encountered', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('suggestions', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('before_image_path', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('after_image_path', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('processed', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('processed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('used_for_training', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['analysis_id'], ['ml_image_analyses.analysis_id'], name=op.f('user_feedback_analysis_id_fkey')),
    sa.ForeignKeyConstraint(['session_id'], ['ml_analysis_sessions.session_id'], name=op.f('user_feedback_session_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('user_feedback_pkey'))
    )
    op.create_index(op.f('ix_user_feedback_feedback_id'), 'user_feedback', ['feedback_id'], unique=True)
    op.create_table('training_datasets',
    sa.Column('id', sa.INTEGER(), server_default=sa.text("nextval('training_datasets_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('dataset_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('version', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('description', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('total_samples', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('class_distribution', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('quality_threshold', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('train_samples', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('validation_samples', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('test_samples', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('augmentation_enabled', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('augmentation_config', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('mean_confidence', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('annotation_sources', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('parent_dataset_id', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('changes_from_parent', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('export_formats', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('export_paths', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_by', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('is_active', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='training_datasets_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('ix_training_datasets_dataset_id'), 'training_datasets', ['dataset_id'], unique=True)
    op.create_table('c_avg_dataset',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('variety', postgresql.ENUM('SRI_WIJAYA', 'SRI_GAMUNU', 'CEYLON', 'LOCAL', name='cinnamonvariety'), autoincrement=False, nullable=False),
    sa.Column('location', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('age_years', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('avg_rainfall_mm', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('avg_temp_c', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('soil_type', postgresql.ENUM('SANDY_LOAM', 'CLAY_LOAM', 'RED_EARTH', 'ALLUVIAL', 'LATERITE', name='soiltype'), autoincrement=False, nullable=False),
    sa.Column('N_Def_Flag', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('P_Def_Flag', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('K_Def_Flag', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('Disease_Flag', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('Cane_Sum', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('Trees_Samp', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('C_avg', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('data_source', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('collection_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('quality_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('notes', sa.VARCHAR(length=500), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('c_avg_dataset_pkey'))
    )
    op.create_table('continuous_learning_config',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('config_name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('is_active', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('min_feedback_samples', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('feedback_accuracy_threshold', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('time_based_retraining_days', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('min_accuracy_improvement', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('max_training_time_hours', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('validation_accuracy_threshold', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('test_accuracy_threshold', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('user_acceptance_threshold', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('performance_monitoring_enabled', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('alert_on_performance_drop', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('performance_drop_threshold', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('keep_model_versions', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('auto_rollback_enabled', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('rollback_accuracy_threshold', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('created_by', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('last_modified_by', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('continuous_learning_config_pkey'))
    )
    op.create_index(op.f('ix_continuous_learning_config_config_name'), 'continuous_learning_config', ['config_name'], unique=True)
    op.create_table('model_performance_metrics',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('metric_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('deployment_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('measurement_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('period_start', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('period_end', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('total_predictions', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('accuracy', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('precision', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('recall', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('f1_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('class_accuracies', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('class_precisions', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('class_recalls', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('user_satisfaction_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('recommendation_effectiveness', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('average_response_time_ms', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('error_rate', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('data_drift_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('concept_drift_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('low_confidence_predictions', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('confidence_threshold', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('calculated_by', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['deployment_id'], ['model_deployments.deployment_id'], name=op.f('model_performance_metrics_deployment_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('model_performance_metrics_pkey'))
    )
    op.create_index(op.f('ix_model_performance_metrics_metric_id'), 'model_performance_metrics', ['metric_id'], unique=True)
    # ### end Alembic commands ###
